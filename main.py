import os
import re
import requests
import datetime
import zipfile
import tempfile
from functools import wraps
from concurrent.futures import ThreadPoolExecutor
from time import sleep
from base64 import b64decode
from Crypto.Cipher import AES
from Crypto.Util.Padding import unpad
from ebooklib import epub

# é…ç½®ä¿¡æ¯
API_BASE = "https://qimao.tutublog.eu.org"  # ä¸ƒçŒ«å°è¯´APIåŸºç¡€åœ°å€
AES_KEY = bytes.fromhex("32343263636238323330643730396531")  # AESè§£å¯†å¯†é’¥


def retry(max_retries=3, delay=2, exceptions=(Exception,)):
	"""é‡è¯•è£…é¥°å™¨ï¼šåœ¨é‡åˆ°æŒ‡å®šå¼‚å¸¸æ—¶è‡ªåŠ¨é‡è¯•å‡½æ•°è°ƒç”¨"""

	def decorator(func):
		@wraps(func)
		def wrapper(*args, **kwargs):
			retries = 0
			while retries < max_retries:
				try:
					return func(*args, **kwargs)
				except exceptions as e:
					retries += 1
					sleep(delay)
			return func(*args, **kwargs)  # æœ€åä¸€æ¬¡å°è¯•ä¸æ•è·å¼‚å¸¸

		return wrapper

	return decorator


class QimaoAutoProcessor:
	"""ä¸ƒçŒ«å°è¯´è‡ªåŠ¨åŒ–ä¸‹è½½"""

	def __init__(self):
		# è¯·æ±‚å¤´é…ç½®
		self.headers = {
			"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/125.0.0.0 Safari/537.36",
			"Referer": "https://www.qimao.com/",
		}
		self.novel_meta = {}  # å­˜å‚¨å°è¯´å…ƒæ•°æ®
		self.temp_dir = tempfile.TemporaryDirectory()  # åˆ›å»ºä¸´æ—¶ç›®å½•
		self.novel_subdir = ""  # å°è¯´ä¸“å±è¾“å‡ºç›®å½•
		self.book_id = ""  # å½“å‰å¤„ç†çš„å°è¯´ID
		self.catalog = {}  # ç« èŠ‚ç›®å½•å­—å…¸ï¼ˆchapter_id: titleï¼‰
		self.failed_files = []  # è®°å½•å¤„ç†å¤±è´¥çš„æ–‡ä»¶

	@staticmethod
	def sanitize_filename(filename: str) -> str:
		"""æ¸…ç†éæ³•æ–‡ä»¶åå­—ç¬¦ï¼Œæ›¿æ¢ä¸ºä¸‹åˆ’çº¿"""
		return re.sub(r'[\\/*?"<>|:]', '_', filename)

	def parse_book_id(self, input_str: str) -> str:
		"""ä»ç”¨æˆ·è¾“å…¥ä¸­è§£æå°è¯´IDï¼Œæ”¯æŒç›´æ¥è¾“å…¥IDæˆ–URL"""
		patterns = [
			r"www.qimao.com/shuku/(\d+)",  # åŒ¹é…URLæ ¼å¼
			r"^(\d+)$"  # åŒ¹é…çº¯æ•°å­—ID
		]
		for pattern in patterns:
			match = re.search(pattern, input_str)
			if match:
				return match.group(1)
		raise ValueError("æ— æ•ˆè¾“å…¥ï¼Œè¯·è¾“å…¥æ­£ç¡®çš„å°è¯´IDæˆ–é“¾æ¥")

	# æœç´¢åŠŸèƒ½ -------------------------------------------------
	@retry(max_retries=2)
	def search_novel(self, keyword: str) -> str:
		"""æœç´¢å°è¯´å¹¶è¿”å›é€‰æ‹©çš„ä¹¦ç±ID"""
		try:
			search_url = f"{API_BASE}/search?wd={keyword}"
			response = requests.get(search_url, headers=self.headers)
			response.raise_for_status()
			data = response.json()

			books = data.get("data", {}).get("books", [])
			if not books:
				print("âš ï¸ æœªæ‰¾åˆ°ç›¸å…³ä¹¦ç±")
				return ""

			print(f"\næ‰¾åˆ° {len(books)} æ¡ç»“æœï¼š")
			for idx, book in enumerate(books[:10]):  # æœ€å¤šæ˜¾ç¤ºå‰10æ¡
				title = book.get("original_title", "æœªçŸ¥æ ‡é¢˜")
				author = book.get("author", "æœªçŸ¥ä½œè€…")
				words = book.get("words_num", "æœªçŸ¥å­—æ•°")
				status = "å®Œç»“" if book.get("is_over") == "1" else "è¿è½½"
				print(f"[{idx + 1}] {title} - {author} ({words}å­—, {status})")

			# å¤„ç†ç”¨æˆ·é€‰æ‹©
			while True:
				choice = input("\nè¯·è¾“å…¥åºå·é€‰æ‹©ä¹¦ç± (r-é‡æ–°æœç´¢/q-é€€å‡º): ").lower()
				if choice == 'r':
					return ""
				elif choice == 'q':
					return "exit"
				elif choice.isdigit():
					index = int(choice) - 1
					if 0 <= index < len(books):
						# return books[index]["id"]
						self.novel_meta = books[index]
						return books[index]["id"]
					print("âš ï¸ æ— æ•ˆçš„åºå·")
				else:
					print("âš ï¸ æ— æ•ˆè¾“å…¥")
		except Exception as e:
			print(f"ğŸ”´ æœç´¢å¤±è´¥: {str(e)}")
			return ""

	# ä¸»è¿è¡Œæµç¨‹ ------------------------------------------
	def run(self, user_input: str = "", output_dir: str = "output") -> None:
		"""ä¸»è¿è¡Œæµç¨‹"""
		try:
			# æœç´¢æ¨¡å¼
			if not user_input:
				while True:
					mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1-ç›´æ¥è¾“å…¥ 2-æœç´¢): ").strip()
					if mode == "1":
						user_input = input("è¯·è¾“å…¥å°è¯´IDæˆ–é“¾æ¥ï¼š").strip()
						break
					elif mode == "2":
						keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼š").strip()
						if not keyword:
							print("æœç´¢è¯ä¸èƒ½ä¸ºç©º")
							continue
						book_id = self.search_novel(keyword)
						if book_id == "exit":
							return
						if book_id:
							user_input = book_id
							break
					else:
						print("æ— æ•ˆçš„è¾“å…¥")

			# ä¸‹è½½å°è¯´
			self.book_id = self.parse_book_id(user_input)
			extract_dir = self.download_novel()
			self.get_metadata()

			# åˆ›å»ºå°è¯´ä¸“å±ç›®å½•ï¼šoutput/book_id/
			# self.novel_subdir = os.path.join(output_dir, self.book_id)
			self.novel_subdir = os.path.join(output_dir)
			os.makedirs(self.novel_subdir, exist_ok=True)

			print(f"\næ­£åœ¨å¤„ç†ã€Š{self.novel_meta['title']}ã€‹")
			self.get_chapters()
			self.process_files(extract_dir, self.novel_subdir)
		except Exception as e:
			print(f"\nå¤„ç†å¤±è´¥ï¼š{str(e)}")
		finally:
			self.temp_dir.cleanup()  # ç¡®ä¿æ¸…ç†ä¸´æ—¶ç›®å½•

	# ä¸»åŠŸèƒ½ ----------------------------------------
	@retry(max_retries=3, exceptions=(requests.exceptions.RequestException,))
	def get_download_url(self) -> str:
		"""è·å–å°è¯´å‹ç¼©åŒ…çš„ä¸‹è½½ç›´é“¾"""
		try:
			response = requests.get(
				f"{API_BASE}/{self.book_id}",
				headers=self.headers,
				allow_redirects=False,
				timeout=15
			)
			if response.status_code == 302:
				return response.headers['Location']
			raise RuntimeError(f"éé¢„æœŸçŠ¶æ€ç : {response.status_code}")
		except Exception as e:
			raise RuntimeError(f"ä¸‹è½½é“¾æ¥è·å–å¤±è´¥: {str(e)}")

	def download_novel(self) -> str:
		"""å®Œæ•´ä¸‹è½½æµç¨‹"""
		print("[1/5] æ­£åœ¨è·å–ä¸‹è½½é“¾æ¥...")
		download_url = self.get_download_url()

		print("[2/5] æ­£åœ¨ä¸‹è½½æ–‡ä»¶...")
		zip_path = os.path.join(self.temp_dir.name, f"{self.book_id}.zip")

		# æµå¼ä¸‹è½½å¤§æ–‡ä»¶
		response = requests.get(download_url, stream=True)
		with open(zip_path, 'wb') as f:
			for chunk in response.iter_content(chunk_size=8192):
				if chunk:
					f.write(chunk)

		print("[3/5] æ­£åœ¨è§£å‹æ–‡ä»¶...")
		extract_dir = os.path.join(self.temp_dir.name, "extracted")
		with zipfile.ZipFile(zip_path, 'r') as zip_ref:
			zip_ref.extractall(extract_dir)

		return extract_dir

	def get_metadata(self) -> None:
		"""è·å–å°è¯´å…ƒæ•°æ®"""
		try:
			data = self.novel_meta
			# ä¹¦å
			book_name = data['original_title']
			# ä½œè€…
			book_author = data['author']
			# æ ‡ç­¾
			book_tag = data.get("ptags").split(",")
			# å›¾ç‰‡
			book_image = data.get("image_link")
			# å­—æ•°
			words_num = "æœªçŸ¥å­—æ•°" if data.get("words_num") is None else data.get("words_num")
			# ID
			book_id = data.get("id")
			# ç®€ä»‹
			book_info = data.get("intro").replace("<br>", "\n")
			# æ—¶é—´æˆ³
			# update_time = datetime.datetime.fromtimestamp(int(data["update_time"])).strftime("%Y-%m-%d %H:%M:%S")

			self.novel_meta = {
				"title": book_name,
				"author": book_author,
				"image_link": book_image,
				# "big_image_link": data.get("big_image_link", ""),
				"tags": book_tag,
				"words_num": words_num,
				"book_id": book_id,
				"intro": book_info,
				# "update_time": update_time
			}
		except Exception as e:
			self.novel_meta = {
				"title": "æœªçŸ¥ä¹¦å",
				"author": "æœªçŸ¥ä½œè€…",
				"image_link": "",
				"tags": [],
				"words_num": "æœªçŸ¥",
				"book_id": self.book_id,
				"intro": "æ— ç®€ä»‹",
				# "update_time": datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
			}

	@retry(max_retries=3)
	def get_chapters(self) -> None:
		"""è·å–ç« èŠ‚ç›®å½•ä¿¡æ¯"""
		try:
			response = requests.get(
				f"{API_BASE}/book/{self.book_id}/chapters",
				headers=self.headers,
				timeout=15
			)
			chapters = response.json()["data"]["chapters"]
			self.catalog = {chap["id"]: chap["title"] for chap in sorted(
				chapters, key=lambda x: int(x["chapter_sort"])
			)}
		except Exception as e:
			raise RuntimeError(f"ç›®å½•è·å–å¤±è´¥: {str(e)}")

	def _process_single_file(self, filename):
		"""å•æ–‡ä»¶å¤„ç†æµç¨‹"""
		try:
			chapter_id = os.path.splitext(filename)[0]
			original_path = os.path.join(self.extract_dir, filename)

			content = '    ' + self.decrypt_file(original_path)
			content = content.replace("\n", "\n    ")
			chapter_title = self.catalog.get(chapter_id, f"æœªçŸ¥ç« èŠ‚_{chapter_id}")
			clean_title = self.sanitize_filename(chapter_title)

			output_path = os.path.join(self.novel_subdir, f"{clean_title}.txt")
			with open(output_path, "w", encoding="utf-8") as f:
				f.write(content)

			return (chapter_id, chapter_title, output_path)
		except Exception as e:
			self.failed_files.append(filename)
			return None

	def decrypt_file(self, input_path: str) -> str:
		"""AESè§£å¯†æ–‡ä»¶å†…å®¹"""
		with open(input_path, "r", encoding="utf-8") as f:
			encrypted = f.read()

		raw = b64decode(encrypted)
		iv, data = raw[:16], raw[16:]
		cipher = AES.new(AES_KEY, AES.MODE_CBC, iv=iv)
		return unpad(cipher.decrypt(data), AES.block_size).decode("utf-8")

	def process_files(self, extract_dir: str, output_dir: str) -> None:
		"""æ‰¹é‡å¤„ç†è§£å‹åçš„æ–‡ä»¶"""
		self.novel_subdir = output_dir
		self.extract_dir = extract_dir
		os.makedirs(self.novel_subdir, exist_ok=True)
		decrypted_files = []

		file_list = sorted([f for f in os.listdir(extract_dir) if f.endswith(".txt")],
		                   key=lambda x: int(x.split('.')[0]))

		print("[4/5] æ­£åœ¨å¤„ç†æ–‡ä»¶...")
		with ThreadPoolExecutor(max_workers=8) as executor:
			futures = [executor.submit(self._process_single_file, f) for f in file_list]
			for future in futures:
				result = future.result()
				if result:
					decrypted_files.append(result)

		if decrypted_files:
			merged_path = self.merge_files(sorted(decrypted_files, key=lambda x: int(x[0])))
			# self.generate_epub(decrypted_files, merged_path)
			self.clean_temp_files(merged_path)

		if self.failed_files:
			print(f"\nå¤±è´¥æ–‡ä»¶æ•°: {len(self.failed_files)}")
			for f in self.failed_files[:3]:
				print(f"å¤±è´¥ç¤ºä¾‹: {f}")

	def merge_files(self, files: list) -> str:
		"""åˆå¹¶æ‰€æœ‰ç« èŠ‚ä¸ºå•ä¸ªtxtæ–‡ä»¶"""
		meta_header = f"""ä¹¦åï¼š{self.novel_meta['title']}
ä½œè€…ï¼š{self.novel_meta['author']}
æ ‡ç­¾ï¼š{'ã€'.join(self.novel_meta['tags'])}
å­—æ•°ï¼š{self.novel_meta['words_num']}
ä¹¦ç±IDï¼š{self.novel_meta['book_id']}
ç®€ä»‹ï¼š
{self.novel_meta['intro']}

{"=" * 50}
"""
		novel_name = f"{self.sanitize_filename(self.novel_meta['title'])}.txt"
		output_path = os.path.join(self.novel_subdir, novel_name)

		with open(output_path, "w", encoding="utf-8") as f:
			f.write(meta_header)
			for _, title, path in files:
				with open(path, "r", encoding="utf-8") as cf:
					f.write(f"\n\n{title}\n\n")
					f.write(cf.read())

		return output_path

	def download_cover(self) -> bytes:
		"""ä¸‹è½½å°é¢å›¾ç‰‡"""
		image_url = self.novel_meta.get("big_image_link") or self.novel_meta.get("image_link")
		if not image_url:
			return b""

		try:
			response = requests.get(image_url, timeout=10)
			response.raise_for_status()
			return response.content
		except Exception as e:
			print(f"å°é¢ä¸‹è½½å¤±è´¥: {str(e)}")
			return b""

	def generate_epub(self, files: list, merged_path: str) -> None:
		"""ç”ŸæˆEPUBç”µå­ä¹¦"""
		print("[5/5] æ­£åœ¨ç”ŸæˆEPUB...")
		book = epub.EpubBook()
		book.set_title(self.novel_meta["title"])
		book.add_author(self.novel_meta["author"])
		book.set_language("zh-CN")

		style = '''
        body { 
            font-family: "Microsoft YaHei", sans-serif; 
            line-height: 1.8;
            margin: 2em;
        }
        h1 { 
            font-size: 1.8em; 
            border-bottom: 1px solid #ccc;
            padding-bottom: 0.5em;
        }
        .content {
            white-space: pre-wrap;
            margin-top: 1.5em;
        }
        '''
		nav_css = epub.EpubItem(
			uid="style_nav",
			file_name="style/nav.css",
			media_type="text/css",
			content=style
		)
		book.add_item(nav_css)

		cover_data = self.download_cover()
		if cover_data:
			try:
				book.set_cover("cover.jpg", cover_data)
			except Exception as e:
				print(f"å°é¢å¤„ç†å¤±è´¥: {str(e)}")

		toc = []
		chapters = []

		intro_html = epub.EpubHtml(title="ç®€ä»‹", file_name="intro.xhtml")
		intro_content = f"""
        <h1>{self.novel_meta['title']}</h1>
        {"<img src='cover.jpg' alt='å°é¢' style='max-width: 80%;'/>" if cover_data else ""}
        <div class="content">{self.novel_meta['intro']}</div>
        """
		intro_html.content = intro_content
		book.add_item(intro_html)
		chapters.append(intro_html)

		future_data = []
		with ThreadPoolExecutor(max_workers=4) as executor:
			for idx, (_, original_title, path) in enumerate(files, 1):
				future = executor.submit(
					self._create_epub_chapter,
					original_title,
					path,
					idx,
					nav_css
				)
				future_data.append((future, original_title, idx))

			for future, chapter_title, chapter_idx in future_data:
				chapter = future.result()
				book.add_item(chapter)
				chapters.append(chapter)
				toc.append(epub.Link(
					href=chapter.file_name,
					title=chapter_title,
					uid=f"chap_{chapter_idx}"
				))

		book.toc = tuple(toc)
		book.add_item(epub.EpubNav())
		book.add_item(epub.EpubNcx())
		book.spine = ['nav', intro_html] + chapters

		epub_name = f"{self.sanitize_filename(self.novel_meta['title'])}.epub"
		epub_path = os.path.join(self.novel_subdir, epub_name)
		epub.write_epub(epub_path, book)
		print(f"EPUBç”Ÿæˆå®Œæˆï¼š{epub_path}")

	def _create_epub_chapter(self, title, path, idx, css):
		"""åˆ›å»ºå•ä¸ªEPUBç« èŠ‚"""
		with open(path, "r", encoding="utf-8") as f:
			content = f.read().replace('\n', '<br/>')

		chapter = epub.EpubHtml(
			title=title,
			file_name=f"chap_{idx}.xhtml",
			lang='zh-CN'
		)
		chapter.content = f"""
        <h1>{title}</h1>
        <div class="content">{content}</div>
        """
		chapter.add_item(css)
		return chapter

	def clean_temp_files(self, merged_path: str) -> None:
		"""æ¸…ç†ä¸­é—´æ–‡ä»¶"""
		temp_files = [f for f in os.listdir(self.novel_subdir)
		              if f.endswith(".txt") and os.path.join(self.novel_subdir, f) != merged_path]

		print("æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
		for f in temp_files:
			try:
				os.remove(os.path.join(self.novel_subdir, f))
			except:
				pass


if __name__ == "__main__":
	processor = QimaoAutoProcessor()
	print("=== ä¸ƒçŒ«å°è¯´ä¸‹è½½å™¨ ===")

	mode = input("è¯·é€‰æ‹©æ¨¡å¼ (1-ç›´æ¥è¾“å…¥ 2-æœç´¢): ").strip()

	if mode == "1":
		user_input = input("è¯·è¾“å…¥å°è¯´IDæˆ–é“¾æ¥ï¼š").strip()
		output_dir = input("è¾“å‡ºç›®å½•: ").strip() or "book"
		processor.run(user_input, output_dir)
	elif mode == "2":
		keyword = input("è¯·è¾“å…¥æœç´¢å…³é”®è¯ï¼š").strip()
		book_id = processor.search_novel(keyword)
		if book_id and book_id != "exit":
			output_dir = input("è¾“å‡ºç›®å½•: ").strip() or "book"
			processor.run(book_id, output_dir)
	else:
		print("æ— æ•ˆçš„é€‰æ‹©")

	print("\nå¤„ç†å®Œæˆï¼")
